{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep kernel learning example on STEM data\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pycroscopy/DTMicroscope/blob/main/notebooks/STEM/2_active_learning_dkl_COLAB-Hackathon.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyro5\n",
    "!pip install scifireaders\n",
    "!pip install sidpy\n",
    "!pip install pynsid\n",
    "!pip install git+https://github.com/pycroscopy/DTMicroscope.git@utk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!run_server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active learning in STEM\n",
    "\n",
    "One significant challenge in STEM is that it is not always possible to acquire spectroscopy across a dense grid of points due to the beam causing sample damage. Even in cases where there is little damage, this method is still highly wasteful. Instead, it is useful to be able to adaptively sample to maximize some property of interest. This example shows how deep kernel learning can be used for this adaptive sampling/optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client side starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install atomai\n",
    "!pip install gpax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import Pyro5.api\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from atomai.utils import get_coord_grid, extract_patches_and_spectra, extract_subimages\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import gpax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the microscope server\n",
    "uri = \"PYRO:microscope.server@localhost:9091\"\n",
    "mic_server = Pyro5.api.Proxy(uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Download data and register\n",
    "!wget https://github.com/pycroscopy/DTMicroscope/raw/utk/data/STEM/SI/test_stem.h5\n",
    "mic_server.initialize_microscope(\"STEM\")\n",
    "mic_server.register_data(\"test_stem.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = mic_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_features(img, window_size):\n",
    "    coordinates = get_coord_grid(img, step = 1, return_dict=False)\n",
    "    features_all, coords, _ = extract_subimages(img, coordinates, window_size)\n",
    "    features_all = features_all[:,:,:,0]\n",
    "    coords = np.array(coords, dtype=int)\n",
    "    norm_ = lambda x: (x - x.min()) / x.ptp()\n",
    "    features = norm_(features_all)\n",
    "    return features, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overview image\n",
    "array_list, shape, dtype = mic_server.get_overview_image()\n",
    "img = np.array(array_list, dtype=dtype).reshape(shape)\n",
    "\n",
    "n, d1, d2 = features.shape\n",
    "X = features.reshape(n, d1*d2)\n",
    "plt.imshow(img)# shape is 55,70\n",
    "plt.scatter(60, 25, s=1, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only 0.02% of grid data points as initial training points\n",
    "(X_measured, X_unmeasured, indices_measured, indices_unmeasured) = train_test_split(\n",
    "    X, indices_all, test_size=0.990, shuffle=True, random_state=3)\n",
    "\n",
    "seed_points = len(X_measured)\n",
    "\n",
    "print(\"Seed points: \", seed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_range_01 = [0.35, 0.55]# dipole mode\n",
    "energy_range_02 = [0.6, 0.75]# edge mode\n",
    "energy_range_03 = [0.8, 1.0]# bulk mode\n",
    "spectral_img = mic.get_spectrum_image(channel_key=\"Channel_001\")\n",
    "E_axis = spectral_img.dim_2.values\n",
    "e1a, e1b = abs(E_axis - energy_range_01[0]).argmin(), abs(E_axis - energy_range_01[1]).argmin()# 2 numbers\n",
    "e2a, e2b = abs(E_axis - energy_range_02[0]).argmin(), abs(E_axis - energy_range_02[1]).argmin()# 2 numbers\n",
    "e3a, e3b = abs(E_axis - energy_range_03[0]).argmin(), abs(E_axis - energy_range_03[1]).argmin()# 2 numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_y_pred = np.sum(spectral_img[:, :, e1a:e1b], axis=2)\n",
    "# Normalize the entire array\n",
    "norm_ = lambda x: (x - np.min(x)) / np.ptp(x)\n",
    "reference_y_pred = norm_(reference_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri\n",
    "y_measured_unnor = []\n",
    "for i in range (seed_points):\n",
    "    # converted_coords = newexp.convert_coordinates(indices_measured[i,::-1], num_pix_x = 192, num_pix_y = 192)\n",
    "    # wv, quick_fit, cx, chns = newexp.do_beps_specific(coordinates = converted_coords,\n",
    "    #                                                 file_name = \"BEPS_seed_{}\".format(i))\n",
    "    # amp_off, amp_on = sep_on_off(np.asarray(quick_fit)[0,0,])\n",
    "    # pha_off, pha_on = sep_on_off(np.asarray(quick_fit)[0,3,])\n",
    "    # current_y = loop_area(amp_off*np.cos(pha_off), 3)\n",
    "    spectrum = mic.get_point_data(\"Channel_001\", indices_measured[i, 0], indices_measured[i, 1])# should the index be reversed?\n",
    "    # choose mean as the scalarizer function\n",
    "    print(spectrum)\n",
    "    current_y = spectrum[e1a:e1b].sum() \n",
    "    y_measured_unnor.append(current_y)\n",
    "    # time.sleep(0.5)\n",
    "    \n",
    "norm_ = lambda x: (x - x.min()) / x.ptp()\n",
    "y_measured = norm_(np.asarray(y_measured_unnor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(img)\n",
    "axes[0].scatter(indices_measured[:, 1], indices_measured[:, 0], c=\"r\", marker = \"X\", s=30)\n",
    "axes[0].set_title('Seed Points')\n",
    "\n",
    "axes[1].imshow(img)\n",
    "axes[1].scatter(indices_measured[:, 1], indices_measured[:, 0], c=y_measured, marker = \"X\", s=30)\n",
    "axes[1].set_title('Seed Points')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def plot_acquisition_and_dkl_prediction(\n",
    "    indices_unmeasured, obj, img, dkl, key1, X, indices_all, reference_scalarizer, file_name, step\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots the acquisition function values, DKL predictions, the original image, \n",
    "    and the reference scalarizer, then saves the plot as a PNG file.\n",
    "\n",
    "    Parameters:\n",
    "    - indices_unmeasured: np.ndarray of unmeasured indices.\n",
    "    - obj: np.ndarray of acquisition function values.\n",
    "    - img: np.ndarray, base image to overlay predictions on.\n",
    "    - dkl: DKL model instance with a predict method.\n",
    "    - key1: Random state or key used in the DKL predict function.\n",
    "    - X: np.ndarray of input data points for DKL prediction.\n",
    "    - indices_all: np.ndarray of all indices used for prediction.\n",
    "    - reference_scalarizer: np.ndarray, reference scalarizer values.\n",
    "    - file_name: str, the file name (without extension) to save the plot as PNG.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 10))  # Create a 2x2 grid of subplots\n",
    "\n",
    "    # Create an image to display acquisition function values using imshow\n",
    "    acq_img = np.zeros_like(img, dtype=float)  # Initialize a grid of zeros with the same shape as the original image\n",
    "\n",
    "    # Fill in the acquisition values at the unmeasured indices\n",
    "    for idx, (i, j) in enumerate(indices_unmeasured):\n",
    "        acq_img[i, j] = obj[idx]\n",
    "\n",
    "    # Plot the acquisition function values using imshow\n",
    "    im1 = ax[0, 0].imshow(acq_img, cmap='viridis')\n",
    "    cbar1 = fig.colorbar(im1, ax=ax[0, 0], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "    cbar1.set_label('Acquisition Function Value')\n",
    "\n",
    "    # Highlight the next point to measure\n",
    "    next_point = indices_unmeasured[obj.argmax()]\n",
    "    ax[0, 0].scatter(next_point[1], next_point[0], marker='x', c='k', s=100)\n",
    "    ax[0, 0].set_title(\"Acquisition Function Values\")\n",
    "    ax[0, 0].set_xlabel('X Index')\n",
    "    ax[0, 0].set_ylabel('Y Index')\n",
    "\n",
    "    # Plot the DKL prediction\n",
    "    y_pred_img = np.zeros((img.shape[0], img.shape[1]))\n",
    "    y_pred_mean, y_pred_std = dkl.predict(key1, np.array(X))\n",
    "\n",
    "    # Fill the prediction image with predicted mean values\n",
    "    for j in range(len(indices_all)):\n",
    "        y_pred_img[indices_all[j][0], indices_all[j][1]] = y_pred_mean[j]\n",
    "\n",
    "    im2 = ax[0, 1].imshow(y_pred_img, cmap='plasma')\n",
    "    cbar2 = fig.colorbar(im2, ax=ax[0, 1], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "    cbar2.set_label('Predicted Mean Value')\n",
    "\n",
    "    ax[0, 1].set_title(\"DKL Prediction\")\n",
    "    ax[0, 1].set_xlabel('X Index')\n",
    "    ax[0, 1].set_ylabel('Y Index')\n",
    "\n",
    "    # Plot the original image\n",
    "    ax[1, 0].imshow(img, cmap='gray')\n",
    "    ax[1, 0].set_title(\"Original Image\")\n",
    "    ax[1, 0].set_xlabel('X Index')\n",
    "    ax[1, 0].set_ylabel('Y Index')\n",
    "\n",
    "    # Plot the reference scalarizer\n",
    "    im3 = ax[1, 1].imshow(reference_scalarizer, cmap='inferno')\n",
    "    cbar3 = fig.colorbar(im3, ax=ax[1, 1], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "    cbar3.set_label('Reference Scalarizer')\n",
    "\n",
    "    ax[1, 1].set_title(\"Reference Scalarizer\")\n",
    "    ax[1, 1].set_xlabel('X Index')\n",
    "    ax[1, 1].set_ylabel('Y Index')\n",
    "\n",
    "    # Calculate MSE between the DKL prediction and the reference scalarizer\n",
    "    mse = mean_squared_error(reference_scalarizer.flatten(), y_pred_img.flatten())\n",
    "    print(f\"Mean Squared Error between DKL Prediction and Reference Scalarizer: {mse:.4f}\")\n",
    "    fig.suptitle(f\" Step_{step}_Mean Squared Error: {mse:.4f}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{file_name} + 'mse' {mse:.4f} .png\")\n",
    "    plt.close(fig)  # Close the figure to free memory\n",
    "\n",
    "data_dim = X_measured.shape[-1]\n",
    "key1, key2 = gpax.utils.get_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(budget):\n",
    "            dkl = gpax.viDKL(data_dim, 2)\n",
    "            # import pdb; pdb.set_trace()\n",
    "            dkl.fit(key1, np.array(X_measured), np.array(y_measured), num_steps=100, step_size=0.05)\n",
    "            obj = gpax.acquisition.UCB(key2, dkl, np.array(X_unmeasured), beta=0.25, maximize=True)\n",
    "            next_point_idx = obj.argmax()\n",
    "            measured_point = mic.get_point_data(\"Channel_001\", indices_measured[i, 0], indices_measured[i, 1])\n",
    "            measured_point = measured_point[e1a:e1b].sum() # scalarizer\n",
    "            \n",
    "            plot_acquisition_and_dkl_prediction(indices_unmeasured, obj, img, dkl, key1, X, indices_all, reference_y_pred, f\"{out_dir}/dkl_pred_acq_{i}\", i)\n",
    "\n",
    "            \n",
    "            \n",
    "            X_measured = np.append(np.array(X_measured), np.array(X_unmeasured)[next_point_idx][None], 0)\n",
    "            X_unmeasured = np.delete(np.array(X_unmeasured), next_point_idx, 0)\n",
    "            y_measured_unnor = np.append(np.array(y_measured_unnor), measured_point)\n",
    "            y_measured = norm_(np.asarray(y_measured_unnor))\n",
    "            # y_unmeasured = np.delete(np.array(y_unmeasured), next_point_idx)\n",
    "            indices_measured = np.append(np.array(indices_measured), np.array(indices_unmeasured)[next_point_idx][None], 0)\n",
    "            indices_unmeasured = np.delete(np.array(indices_unmeasured), next_point_idx, 0)\n",
    "            \n",
    "\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
